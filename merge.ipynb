{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d1ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4314684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"./retrieval_results_heuristic_k5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c201b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_idx</th>\n",
       "      <th>embedding_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>646</td>\n",
       "      <td>Is the smallest penguin species the Little Blu...</td>\n",
       "      <td>953,1182,1192,1204,2595</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>646</td>\n",
       "      <td>Is the smallest penguin species the Little Blu...</td>\n",
       "      <td>952,953,967,975,979</td>\n",
       "      <td>multi-qa-mpnet-base-dot-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>646</td>\n",
       "      <td>Is the smallest penguin species the Little Blu...</td>\n",
       "      <td>950,2467,2471,2596,2642</td>\n",
       "      <td>hkunlp-instructor-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>646</td>\n",
       "      <td>Is the smallest penguin species the Little Blu...</td>\n",
       "      <td>951,952,953,979,981</td>\n",
       "      <td>intfloat-e5-small-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>873</td>\n",
       "      <td>What does a citizen use to propose changes to ...</td>\n",
       "      <td>25,656,657,658,2141</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>794</td>\n",
       "      <td>Are turtles pets?</td>\n",
       "      <td>2684,2688,2692,2693,2698</td>\n",
       "      <td>intfloat-e5-small-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>332</td>\n",
       "      <td>Is he buried in the Princeton Cemetery of the ...</td>\n",
       "      <td>525,699,706,1396,2226</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>332</td>\n",
       "      <td>Is he buried in the Princeton Cemetery of the ...</td>\n",
       "      <td>147,525,567,1967,2999</td>\n",
       "      <td>multi-qa-mpnet-base-dot-v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>332</td>\n",
       "      <td>Is he buried in the Princeton Cemetery of the ...</td>\n",
       "      <td>117,289,567,2718,2903</td>\n",
       "      <td>hkunlp-instructor-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>332</td>\n",
       "      <td>Is he buried in the Princeton Cemetery of the ...</td>\n",
       "      <td>147,188,262,525,3002</td>\n",
       "      <td>intfloat-e5-small-v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     question_id                                      question_text  \\\n",
       "0            646  Is the smallest penguin species the Little Blu...   \n",
       "1            646  Is the smallest penguin species the Little Blu...   \n",
       "2            646  Is the smallest penguin species the Little Blu...   \n",
       "3            646  Is the smallest penguin species the Little Blu...   \n",
       "4            873  What does a citizen use to propose changes to ...   \n",
       "..           ...                                                ...   \n",
       "395          794                                  Are turtles pets?   \n",
       "396          332  Is he buried in the Princeton Cemetery of the ...   \n",
       "397          332  Is he buried in the Princeton Cemetery of the ...   \n",
       "398          332  Is he buried in the Princeton Cemetery of the ...   \n",
       "399          332  Is he buried in the Princeton Cemetery of the ...   \n",
       "\n",
       "                 document_idx            embedding_method  \n",
       "0     953,1182,1192,1204,2595           bert-base-uncased  \n",
       "1         952,953,967,975,979  multi-qa-mpnet-base-dot-v1  \n",
       "2     950,2467,2471,2596,2642     hkunlp-instructor-large  \n",
       "3         951,952,953,979,981        intfloat-e5-small-v2  \n",
       "4         25,656,657,658,2141           bert-base-uncased  \n",
       "..                        ...                         ...  \n",
       "395  2684,2688,2692,2693,2698        intfloat-e5-small-v2  \n",
       "396     525,699,706,1396,2226           bert-base-uncased  \n",
       "397     147,525,567,1967,2999  multi-qa-mpnet-base-dot-v1  \n",
       "398     117,289,567,2718,2903     hkunlp-instructor-large  \n",
       "399      147,188,262,525,3002        intfloat-e5-small-v2  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47ad3468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall avg variation across questions: 0.8935052910052909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3f/f3yfgyxj3csccqmb_dyksc1w0000gn/T/ipykernel_95564/1358113608.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(avg_jaccard_distance_per_question)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# --- helper: turn \"953,1182,1192,1204,2595\" into a set of ints ---\n",
    "def parse_doc_idx(s):\n",
    "    return set(map(int, str(s).split(',')))\n",
    "\n",
    "\n",
    "# --- function to compute avg Jaccard distance inside one question group ---\n",
    "def avg_jaccard_distance_per_question(group: pd.DataFrame) -> float:\n",
    "    sets = group['document_idx'].apply(parse_doc_idx).tolist()\n",
    "    \n",
    "    # if fewer than 2 methods, variation is 0 by convention\n",
    "    if len(sets) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    dists = []\n",
    "    for A, B in combinations(sets, 2):\n",
    "        inter = len(A & B)\n",
    "        union = len(A | B)\n",
    "        jaccard_sim = inter / union if union > 0 else 0.0\n",
    "        dists.append(1.0 - jaccard_sim)  # Jaccard distance\n",
    "    \n",
    "    return sum(dists) / len(dists)\n",
    "\n",
    "\n",
    "# --- 1) average variation PER QUESTION ---\n",
    "per_question_variation = (\n",
    "    result.groupby('question_id')\n",
    "      .apply(avg_jaccard_distance_per_question)\n",
    "      .rename('avg_docidx_variation')\n",
    ")\n",
    "\n",
    "# --- 2) overall average variation across all questions (optional) ---\n",
    "overall_avg_variation = per_question_variation.mean()\n",
    "print(\"Overall avg variation across questions:\", overall_avg_variation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a67265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = pd.read_csv(\"result/rag_evaluation_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7897737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>embedding_method</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">cosine_similarity</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bertscore_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.217856</td>\n",
       "      <td>0.380715</td>\n",
       "      <td>0.653507</td>\n",
       "      <td>0.288320</td>\n",
       "      <td>0.739820</td>\n",
       "      <td>0.120993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hkunlp-instructor-large</td>\n",
       "      <td>0.324301</td>\n",
       "      <td>0.439535</td>\n",
       "      <td>0.674187</td>\n",
       "      <td>0.293843</td>\n",
       "      <td>0.771500</td>\n",
       "      <td>0.133702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intfloat-e5-small-v2</td>\n",
       "      <td>0.277485</td>\n",
       "      <td>0.413854</td>\n",
       "      <td>0.659634</td>\n",
       "      <td>0.292439</td>\n",
       "      <td>0.749955</td>\n",
       "      <td>0.120672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi-qa-mpnet-base-dot-v1</td>\n",
       "      <td>0.332001</td>\n",
       "      <td>0.437982</td>\n",
       "      <td>0.694386</td>\n",
       "      <td>0.287651</td>\n",
       "      <td>0.770692</td>\n",
       "      <td>0.128890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             embedding_method  f1_score           cosine_similarity            \\\n",
       "                                   mean       std              mean       std   \n",
       "0           bert-base-uncased  0.217856  0.380715          0.653507  0.288320   \n",
       "1     hkunlp-instructor-large  0.324301  0.439535          0.674187  0.293843   \n",
       "2        intfloat-e5-small-v2  0.277485  0.413854          0.659634  0.292439   \n",
       "3  multi-qa-mpnet-base-dot-v1  0.332001  0.437982          0.694386  0.287651   \n",
       "\n",
       "  bertscore_f1            \n",
       "          mean       std  \n",
       "0     0.739820  0.120993  \n",
       "1     0.771500  0.133702  \n",
       "2     0.749955  0.120672  \n",
       "3     0.770692  0.128890  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([result,eval],axis=1).groupby('embedding_method').agg({'f1_score':['mean','std'],'cosine_similarity':['mean','std'],'bertscore_f1':['mean','std']}).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
